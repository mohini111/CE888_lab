{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Exercise_1_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohini111/CE888_lab/blob/main/CNNLAB_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwRGEQbzGpYQ"
      },
      "source": [
        "# First CNN model for MNIST Dataset\n",
        "\n",
        "* MNIST Dataset is ''Hello World'' of Image Recognition\n",
        "\n",
        "* [Dataset HomePage](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "* History of MNIST Dataset [Watch here](https://www.youtube.com/watch?v=oKzNUGz21JM)\n",
        "\n",
        "\n",
        "---\n",
        "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a \n",
        "test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "![Kitten](https://camo.githubusercontent.com/01c057a753e92a9bc70b8c45d62b295431851c09cffadf53106fc0aea7e2843f/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmJOHCpJD_w"
      },
      "source": [
        "# Let's start building our first CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyHCSV7jymI"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNzCYUUjymN"
      },
      "source": [
        "Importantly, a convnet takes as input tensors of shape (image_height, image_width,\n",
        "image_channels) (not including the batch dimension). In this case, we’ll configure\n",
        "the convnet to process inputs of size (28, 28, 1), which is the format of MNIST\n",
        "images. We’ll do this by passing the argument input_shape=(28, 28, 1) to the first\n",
        "layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4JLEpwjymN"
      },
      "source": [
        "#### Instantiating a small convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-OnpExGjymO",
        "outputId": "d6b059af-ad81-48a0-ff50-c569e59dde11"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gcVG3xkjymR"
      },
      "source": [
        "#### Adding a classifier on top of the convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2DfhDJYjymR",
        "outputId": "e76d7ecc-142f-4840-eb59-46ed8111b604"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKVF4nKjymU"
      },
      "source": [
        "### Training the convnet on MNIST images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcgUbbUjymV"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnJ2Pfs_jymX"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpHGHE9MjymY"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HoTLrfSjymd"
      },
      "source": [
        "#### compile and fit model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i23FDtC9jyme",
        "outputId": "0a018824-bd9d-4724-cefc-fe3b7ef6e9e9"
      },
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 6s 5ms/step - loss: 0.4526 - accuracy: 0.8558 - val_loss: 0.0595 - val_accuracy: 0.9819\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.0483 - val_accuracy: 0.9852\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0506 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0379 - val_accuracy: 0.9901\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0350 - val_accuracy: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zU8iI5ojymg"
      },
      "source": [
        "#### evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3VeaL1Njymh",
        "outputId": "921e94f4-392f-4776-8173-51394cc5589f"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9927999973297119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "wXNZOY7Sjymj",
        "outputId": "abedd27c-eb17-4f3c-8f6b-036d993d3900"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQMc0Iojyml"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Change the activation function and other parameters such as optimizer to see the effect on the network and it's performance. If possible create a grid search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz-kf8YTlakz"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "activation = ['relu', 'tanh']\n",
        "optimizer = ['rmsprop', 'Adam']\n",
        "\n",
        "def exercise1(activation=activation, optimizer=optimizer):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3,3), activation=activation, input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3,3), activation=activation))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3,3), activation=activation))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation=activation))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "epochs = [5, 10]\n",
        "model = KerasClassifier(build_fn=exercise1, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyfHQYiyonYq",
        "outputId": "73ba3864-2815-4f04-cf6c-10351587d255"
      },
      "source": [
        "param_grid = {\n",
        "     'epochs': epochs,\n",
        "     'activation': activation,\n",
        "     'optimizer': optimizer\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=1, verbose=2)\n",
        "grid_search.fit(train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "[CV] activation=relu, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5036 - accuracy: 0.8373 - val_loss: 0.0726 - val_accuracy: 0.9784\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 0.0612 - val_accuracy: 0.9816\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0443 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0466 - val_accuracy: 0.9870\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0483 - val_accuracy: 0.9884\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9870\n",
            "[CV] ..... activation=relu, epochs=5, optimizer=rmsprop, total=  14.0s\n",
            "[CV] activation=relu, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5118 - accuracy: 0.8344 - val_loss: 0.0709 - val_accuracy: 0.9784\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.0485 - val_accuracy: 0.9856\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0428 - val_accuracy: 0.9873\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0358 - val_accuracy: 0.9903\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9904\n",
            "[CV] ..... activation=relu, epochs=5, optimizer=rmsprop, total=  14.2s\n",
            "[CV] activation=relu, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5280 - accuracy: 0.8309 - val_loss: 0.0732 - val_accuracy: 0.9804\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0688 - accuracy: 0.9788 - val_loss: 0.0566 - val_accuracy: 0.9837\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.0540 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0432 - val_accuracy: 0.9882\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0492 - val_accuracy: 0.9876\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9861\n",
            "[CV] ..... activation=relu, epochs=5, optimizer=rmsprop, total=  13.9s\n",
            "[CV] activation=relu, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5336 - accuracy: 0.8247 - val_loss: 0.0685 - val_accuracy: 0.9799\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.0566 - val_accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0494 - val_accuracy: 0.9854\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0396 - val_accuracy: 0.9874\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0401 - val_accuracy: 0.9899\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9877\n",
            "[CV] ..... activation=relu, epochs=5, optimizer=rmsprop, total=  14.2s\n",
            "[CV] activation=relu, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5032 - accuracy: 0.8343 - val_loss: 0.0903 - val_accuracy: 0.9718\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.0768 - val_accuracy: 0.9766\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.0494 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.0459 - val_accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0593 - val_accuracy: 0.9825\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9873\n",
            "[CV] ..... activation=relu, epochs=5, optimizer=rmsprop, total=  14.5s\n",
            "[CV] activation=relu, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.8401 - val_loss: 0.0795 - val_accuracy: 0.9774\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0659 - accuracy: 0.9797 - val_loss: 0.0573 - val_accuracy: 0.9830\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0538 - val_accuracy: 0.9852\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.0510 - val_accuracy: 0.9859\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0471 - val_accuracy: 0.9859\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.9862\n",
            "[CV] ........ activation=relu, epochs=5, optimizer=Adam, total=  13.2s\n",
            "[CV] activation=relu, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5277 - accuracy: 0.8412 - val_loss: 0.0755 - val_accuracy: 0.9793\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9763 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0511 - accuracy: 0.9843 - val_loss: 0.0548 - val_accuracy: 0.9834\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.0411 - val_accuracy: 0.9881\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0355 - val_accuracy: 0.9894\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9898\n",
            "[CV] ........ activation=relu, epochs=5, optimizer=Adam, total=  12.9s\n",
            "[CV] activation=relu, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5714 - accuracy: 0.8263 - val_loss: 0.1021 - val_accuracy: 0.9703\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0723 - accuracy: 0.9774 - val_loss: 0.0599 - val_accuracy: 0.9825\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0563 - val_accuracy: 0.9828\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9886 - val_loss: 0.0445 - val_accuracy: 0.9869\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0636 - val_accuracy: 0.9825\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9797\n",
            "[CV] ........ activation=relu, epochs=5, optimizer=Adam, total=  13.2s\n",
            "[CV] activation=relu, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5512 - accuracy: 0.8317 - val_loss: 0.0799 - val_accuracy: 0.9757\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.0745 - val_accuracy: 0.9780\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.0515 - val_accuracy: 0.9856\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0604 - val_accuracy: 0.9820\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9794\n",
            "[CV] ........ activation=relu, epochs=5, optimizer=Adam, total=  13.0s\n",
            "[CV] activation=relu, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5281 - accuracy: 0.8366 - val_loss: 0.1073 - val_accuracy: 0.9647\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0690 - accuracy: 0.9779 - val_loss: 0.0669 - val_accuracy: 0.9772\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0397 - accuracy: 0.9869 - val_loss: 0.0515 - val_accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0648 - val_accuracy: 0.9812\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0514 - val_accuracy: 0.9842\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9870\n",
            "[CV] ........ activation=relu, epochs=5, optimizer=Adam, total=  12.9s\n",
            "[CV] activation=relu, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5140 - accuracy: 0.8322 - val_loss: 0.0809 - val_accuracy: 0.9765\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 0.0536 - val_accuracy: 0.9839\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0506 - val_accuracy: 0.9865\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0385 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0432 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0410 - val_accuracy: 0.9894\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0508 - val_accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0654 - val_accuracy: 0.9891\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0577 - val_accuracy: 0.9899\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9887\n",
            "[CV] .... activation=relu, epochs=10, optimizer=rmsprop, total=  26.3s\n",
            "[CV] activation=relu, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5279 - accuracy: 0.8274 - val_loss: 0.0647 - val_accuracy: 0.9812\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0662 - accuracy: 0.9802 - val_loss: 0.0451 - val_accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.0507 - val_accuracy: 0.9847\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0423 - val_accuracy: 0.9887\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.0371 - val_accuracy: 0.9894\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0515 - val_accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9884\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0484 - val_accuracy: 0.9904\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0433 - val_accuracy: 0.9923\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9926\n",
            "[CV] .... activation=relu, epochs=10, optimizer=rmsprop, total=  27.0s\n",
            "[CV] activation=relu, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5263 - accuracy: 0.8266 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.0519 - val_accuracy: 0.9843\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.0502 - val_accuracy: 0.9862\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0445 - val_accuracy: 0.9886\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0350 - val_accuracy: 0.9904\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0381 - val_accuracy: 0.9899\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0399 - val_accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0446 - val_accuracy: 0.9881\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0487 - val_accuracy: 0.9889\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0645 - val_accuracy: 0.9868\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9863\n",
            "[CV] .... activation=relu, epochs=10, optimizer=rmsprop, total=  27.3s\n",
            "[CV] activation=relu, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 4ms/step - loss: 0.5319 - accuracy: 0.8251 - val_loss: 0.0635 - val_accuracy: 0.9817\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.9796 - val_loss: 0.0703 - val_accuracy: 0.9796\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 0.0463 - val_accuracy: 0.9858\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.0469 - val_accuracy: 0.9870\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0381 - val_accuracy: 0.9897\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0543 - val_accuracy: 0.9873\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0490 - val_accuracy: 0.9882\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0433 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0668 - val_accuracy: 0.9880\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9852\n",
            "[CV] .... activation=relu, epochs=10, optimizer=rmsprop, total=  27.2s\n",
            "[CV] activation=relu, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5100 - accuracy: 0.8388 - val_loss: 0.0851 - val_accuracy: 0.9728\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0656 - accuracy: 0.9797 - val_loss: 0.0676 - val_accuracy: 0.9777\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.0509 - val_accuracy: 0.9851\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0476 - val_accuracy: 0.9849\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0428 - val_accuracy: 0.9866\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0514 - val_accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0507 - val_accuracy: 0.9872\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0482 - val_accuracy: 0.9868\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0526 - val_accuracy: 0.9882\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0575 - val_accuracy: 0.9880\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9890\n",
            "[CV] .... activation=relu, epochs=10, optimizer=rmsprop, total=  26.5s\n",
            "[CV] activation=relu, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5634 - accuracy: 0.8255 - val_loss: 0.0694 - val_accuracy: 0.9804\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.9786 - val_loss: 0.0631 - val_accuracy: 0.9820\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0510 - val_accuracy: 0.9864\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.0476 - val_accuracy: 0.9868\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.0505 - val_accuracy: 0.9865\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0367 - val_accuracy: 0.9909\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0459 - val_accuracy: 0.9886\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0543 - val_accuracy: 0.9873\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0455 - val_accuracy: 0.9887\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9890\n",
            "[CV] ....... activation=relu, epochs=10, optimizer=Adam, total=  25.2s\n",
            "[CV] activation=relu, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5680 - accuracy: 0.8307 - val_loss: 0.0698 - val_accuracy: 0.9803\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.9786 - val_loss: 0.0539 - val_accuracy: 0.9832\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9874 - val_loss: 0.0450 - val_accuracy: 0.9858\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0502 - val_accuracy: 0.9867\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0527 - val_accuracy: 0.9847\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0431 - val_accuracy: 0.9879\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0436 - val_accuracy: 0.9884\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0600 - val_accuracy: 0.9849\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0348 - val_accuracy: 0.9907\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9903\n",
            "[CV] ....... activation=relu, epochs=10, optimizer=Adam, total=  25.0s\n",
            "[CV] activation=relu, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.8289 - val_loss: 0.0852 - val_accuracy: 0.9764\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 0.0535 - val_accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 0.0422 - val_accuracy: 0.9876\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.0510 - val_accuracy: 0.9855\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0405 - val_accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0460 - val_accuracy: 0.9868\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0374 - val_accuracy: 0.9902\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0393 - val_accuracy: 0.9903\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9876\n",
            "[CV] ....... activation=relu, epochs=10, optimizer=Adam, total=  25.0s\n",
            "[CV] activation=relu, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5649 - accuracy: 0.8202 - val_loss: 0.0710 - val_accuracy: 0.9789\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9795 - val_loss: 0.0686 - val_accuracy: 0.9797\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0492 - val_accuracy: 0.9865\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0367 - val_accuracy: 0.9901\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0439 - val_accuracy: 0.9885\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0534 - val_accuracy: 0.9881\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9853\n",
            "[CV] ....... activation=relu, epochs=10, optimizer=Adam, total=  25.1s\n",
            "[CV] activation=relu, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5400 - accuracy: 0.8377 - val_loss: 0.1009 - val_accuracy: 0.9676\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0688 - accuracy: 0.9782 - val_loss: 0.0615 - val_accuracy: 0.9803\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0553 - val_accuracy: 0.9826\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0506 - val_accuracy: 0.9854\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0593 - val_accuracy: 0.9839\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0457 - val_accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0525 - val_accuracy: 0.9858\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0560 - val_accuracy: 0.9857\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9887\n",
            "[CV] ....... activation=relu, epochs=10, optimizer=Adam, total=  25.6s\n",
            "[CV] activation=tanh, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3922 - accuracy: 0.8844 - val_loss: 0.0867 - val_accuracy: 0.9741\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0648 - val_accuracy: 0.9808\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.0505 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.0409 - val_accuracy: 0.9878\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0483 - val_accuracy: 0.9867\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9854\n",
            "[CV] ..... activation=tanh, epochs=5, optimizer=rmsprop, total=  14.5s\n",
            "[CV] activation=tanh, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3978 - accuracy: 0.8826 - val_loss: 0.0690 - val_accuracy: 0.9800\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0652 - accuracy: 0.9809 - val_loss: 0.0602 - val_accuracy: 0.9828\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0537 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0469 - val_accuracy: 0.9874\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0560 - val_accuracy: 0.9851\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9824\n",
            "[CV] ..... activation=tanh, epochs=5, optimizer=rmsprop, total=  15.3s\n",
            "[CV] activation=tanh, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.3848 - accuracy: 0.8851 - val_loss: 0.0722 - val_accuracy: 0.9789\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0631 - accuracy: 0.9809 - val_loss: 0.0611 - val_accuracy: 0.9827\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9892 - val_loss: 0.0563 - val_accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0619 - val_accuracy: 0.9825\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0456 - val_accuracy: 0.9881\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9864\n",
            "[CV] ..... activation=tanh, epochs=5, optimizer=rmsprop, total=  14.9s\n",
            "[CV] activation=tanh, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3916 - accuracy: 0.8828 - val_loss: 0.0743 - val_accuracy: 0.9780\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0637 - val_accuracy: 0.9831\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9870\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0461 - val_accuracy: 0.9870\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9846\n",
            "[CV] ..... activation=tanh, epochs=5, optimizer=rmsprop, total=  15.0s\n",
            "[CV] activation=tanh, epochs=5, optimizer=rmsprop ....................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4137 - accuracy: 0.8769 - val_loss: 0.0958 - val_accuracy: 0.9715\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0633 - accuracy: 0.9819 - val_loss: 0.0596 - val_accuracy: 0.9808\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0492 - val_accuracy: 0.9841\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.0516 - val_accuracy: 0.9845\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9849\n",
            "[CV] ..... activation=tanh, epochs=5, optimizer=rmsprop, total=  14.4s\n",
            "[CV] activation=tanh, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4804 - accuracy: 0.8563 - val_loss: 0.0695 - val_accuracy: 0.9799\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.9797 - val_loss: 0.0579 - val_accuracy: 0.9834\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.0674 - val_accuracy: 0.9807\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.0539 - val_accuracy: 0.9842\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0471 - val_accuracy: 0.9867\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9871\n",
            "[CV] ........ activation=tanh, epochs=5, optimizer=Adam, total=  14.2s\n",
            "[CV] activation=tanh, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4947 - accuracy: 0.8541 - val_loss: 0.0778 - val_accuracy: 0.9777\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9787 - val_loss: 0.0638 - val_accuracy: 0.9820\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.0549 - val_accuracy: 0.9856\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.0531 - val_accuracy: 0.9861\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0532 - val_accuracy: 0.9858\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9855\n",
            "[CV] ........ activation=tanh, epochs=5, optimizer=Adam, total=  13.4s\n",
            "[CV] activation=tanh, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4443 - accuracy: 0.8738 - val_loss: 0.0688 - val_accuracy: 0.9810\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9820 - val_loss: 0.0618 - val_accuracy: 0.9818\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9885 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0475 - val_accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0457 - val_accuracy: 0.9877\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9855\n",
            "[CV] ........ activation=tanh, epochs=5, optimizer=Adam, total=  13.3s\n",
            "[CV] activation=tanh, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4619 - accuracy: 0.8680 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.0522 - val_accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.0496 - val_accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0463 - val_accuracy: 0.9871\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9826\n",
            "[CV] ........ activation=tanh, epochs=5, optimizer=Adam, total=  13.7s\n",
            "[CV] activation=tanh, epochs=5, optimizer=Adam .......................\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4527 - accuracy: 0.8698 - val_loss: 0.0820 - val_accuracy: 0.9730\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.9832 - val_loss: 0.0677 - val_accuracy: 0.9804\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0391 - accuracy: 0.9893 - val_loss: 0.0603 - val_accuracy: 0.9809\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.0532 - val_accuracy: 0.9834\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9844\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9863\n",
            "[CV] ........ activation=tanh, epochs=5, optimizer=Adam, total=  14.1s\n",
            "[CV] activation=tanh, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.3959 - accuracy: 0.8842 - val_loss: 0.0730 - val_accuracy: 0.9804\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0631 - accuracy: 0.9812 - val_loss: 0.0593 - val_accuracy: 0.9837\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0569 - val_accuracy: 0.9836\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9864\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0458 - val_accuracy: 0.9875\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0441 - val_accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0446 - val_accuracy: 0.9886\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0439 - val_accuracy: 0.9889\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9894\n",
            "[CV] .... activation=tanh, epochs=10, optimizer=rmsprop, total=  28.4s\n",
            "[CV] activation=tanh, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.3944 - accuracy: 0.8832 - val_loss: 0.0719 - val_accuracy: 0.9786\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0648 - accuracy: 0.9816 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.0496 - val_accuracy: 0.9860\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.0436 - val_accuracy: 0.9880\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0528 - val_accuracy: 0.9853\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0481 - val_accuracy: 0.9866\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0450 - val_accuracy: 0.9873\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0476 - val_accuracy: 0.9886\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0498 - val_accuracy: 0.9874\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0517 - val_accuracy: 0.9881\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.9896\n",
            "[CV] .... activation=tanh, epochs=10, optimizer=rmsprop, total=  29.1s\n",
            "[CV] activation=tanh, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4047 - accuracy: 0.8805 - val_loss: 0.0717 - val_accuracy: 0.9796\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0634 - accuracy: 0.9811 - val_loss: 0.0596 - val_accuracy: 0.9830\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.0493 - val_accuracy: 0.9858\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0457 - val_accuracy: 0.9867\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0464 - val_accuracy: 0.9875\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0441 - val_accuracy: 0.9884\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0469 - val_accuracy: 0.9874\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0451 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0512 - val_accuracy: 0.9882\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9883\n",
            "[CV] .... activation=tanh, epochs=10, optimizer=rmsprop, total=  28.8s\n",
            "[CV] activation=tanh, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.3985 - accuracy: 0.8820 - val_loss: 0.0811 - val_accuracy: 0.9782\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0618 - accuracy: 0.9819 - val_loss: 0.0580 - val_accuracy: 0.9854\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.0602 - val_accuracy: 0.9818\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0480 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0525 - val_accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0489 - val_accuracy: 0.9881\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0503 - val_accuracy: 0.9871\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0483 - val_accuracy: 0.9887\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9858\n",
            "[CV] .... activation=tanh, epochs=10, optimizer=rmsprop, total=  28.9s\n",
            "[CV] activation=tanh, epochs=10, optimizer=rmsprop ...................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3728 - accuracy: 0.8915 - val_loss: 0.0936 - val_accuracy: 0.9702\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.0631 - val_accuracy: 0.9797\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0416 - accuracy: 0.9880 - val_loss: 0.0561 - val_accuracy: 0.9829\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0486 - val_accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0550 - val_accuracy: 0.9839\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0485 - val_accuracy: 0.9852\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0555 - val_accuracy: 0.9859\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0534 - val_accuracy: 0.9861\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0803 - val_accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0650 - val_accuracy: 0.9856\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9875\n",
            "[CV] .... activation=tanh, epochs=10, optimizer=rmsprop, total=  29.1s\n",
            "[CV] activation=tanh, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4729 - accuracy: 0.8595 - val_loss: 0.0716 - val_accuracy: 0.9810\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.9800 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.0513 - val_accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0502 - val_accuracy: 0.9856\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0483 - val_accuracy: 0.9868\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0510 - val_accuracy: 0.9867\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0485 - val_accuracy: 0.9866\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0437 - val_accuracy: 0.9890\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.9887\n",
            "[CV] ....... activation=tanh, epochs=10, optimizer=Adam, total=  26.5s\n",
            "[CV] activation=tanh, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4646 - accuracy: 0.8625 - val_loss: 0.0715 - val_accuracy: 0.9805\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.0539 - val_accuracy: 0.9840\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.0537 - val_accuracy: 0.9849\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9882\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.0480 - val_accuracy: 0.9868\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9881\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0432 - val_accuracy: 0.9889\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9883\n",
            "[CV] ....... activation=tanh, epochs=10, optimizer=Adam, total=  26.6s\n",
            "[CV] activation=tanh, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4503 - accuracy: 0.8669 - val_loss: 0.0713 - val_accuracy: 0.9801\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.9827 - val_loss: 0.0556 - val_accuracy: 0.9832\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0396 - accuracy: 0.9890 - val_loss: 0.0474 - val_accuracy: 0.9858\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0470 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9880\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0433 - val_accuracy: 0.9880\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.0400 - val_accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0554 - val_accuracy: 0.9852\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0443 - val_accuracy: 0.9889\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0487 - val_accuracy: 0.9862\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9866\n",
            "[CV] ....... activation=tanh, epochs=10, optimizer=Adam, total=  27.1s\n",
            "[CV] activation=tanh, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.4591 - accuracy: 0.8720 - val_loss: 0.0723 - val_accuracy: 0.9807\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.9832 - val_loss: 0.0566 - val_accuracy: 0.9826\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0428 - accuracy: 0.9876 - val_loss: 0.0474 - val_accuracy: 0.9864\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0448 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0466 - val_accuracy: 0.9873\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0493 - val_accuracy: 0.9860\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0515 - val_accuracy: 0.9861\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0481 - val_accuracy: 0.9872\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9830\n",
            "[CV] ....... activation=tanh, epochs=10, optimizer=Adam, total=  27.1s\n",
            "[CV] activation=tanh, epochs=10, optimizer=Adam ......................\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4617 - accuracy: 0.8682 - val_loss: 0.0843 - val_accuracy: 0.9750\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.0595 - val_accuracy: 0.9812\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.0555 - val_accuracy: 0.9831\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.0548 - val_accuracy: 0.9837\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0620 - val_accuracy: 0.9801\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0500 - val_accuracy: 0.9847\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0494 - val_accuracy: 0.9851\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0434 - val_accuracy: 0.9873\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0527 - val_accuracy: 0.9858\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9892\n",
            "[CV] ....... activation=tanh, epochs=10, optimizer=Adam, total=  27.0s\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 13.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "750/750 [==============================] - 4s 4ms/step - loss: 0.4653 - accuracy: 0.8496 - val_loss: 0.0651 - val_accuracy: 0.9809\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.0501 - val_accuracy: 0.9859\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 0.0489 - val_accuracy: 0.9851\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0382 - val_accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0474 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0360 - val_accuracy: 0.9909\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.0454 - val_accuracy: 0.9898\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0437 - val_accuracy: 0.9907\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0467 - val_accuracy: 0.9912\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0551 - val_accuracy: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4c37126910>,\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'activation': ['relu', 'tanh'], 'epochs': [5, 10],\n",
              "                         'optimizer': ['rmsprop', 'Adam']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO02Tgk377Os",
        "outputId": "94e1267a-7aaf-4796-d90b-6b3511c9a76f"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9883833289146423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNPwZkIP7-9l",
        "outputId": "eb530afa-123d-4d7a-c422-ee0b5ee30903"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu', 'epochs': 10, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqMuxMJA83ih",
        "outputId": "5828ccb7-4aa3-4ee8-a273-2857e0e5939a"
      },
      "source": [
        "model = exercise1('relu')\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 4ms/step - loss: 0.4469 - accuracy: 0.8616 - val_loss: 0.0664 - val_accuracy: 0.9795\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 0.0434 - val_accuracy: 0.9880\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0407 - val_accuracy: 0.9901\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0436 - val_accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0395 - val_accuracy: 0.9883\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0477 - val_accuracy: 0.9902\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0563 - val_accuracy: 0.9880\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0585 - val_accuracy: 0.9894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrnGFH95ESiI",
        "outputId": "0ec6e90a-8038-4438-c805-dc74219a5f44"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9900000095367432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "9ikj2pagESy3",
        "outputId": "30635cbb-bda0-4d3d-ed78-47f78681e501"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GipjbIHqQs4H"
      },
      "source": [
        "import pandas as pd\n",
        "grid_results = pd.DataFrame(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "TcGxQepsQt6N",
        "outputId": "d19656a2-dad8-4b4b-afe2-82385f701628"
      },
      "source": [
        "grid_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_activation</th>\n",
              "      <th>param_epochs</th>\n",
              "      <th>param_optimizer</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.451987</td>\n",
              "      <td>0.187093</td>\n",
              "      <td>0.711897</td>\n",
              "      <td>0.024392</td>\n",
              "      <td>relu</td>\n",
              "      <td>5</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>{'activation': 'relu', 'epochs': 5, 'optimizer...</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>0.990417</td>\n",
              "      <td>0.986083</td>\n",
              "      <td>0.987667</td>\n",
              "      <td>0.987333</td>\n",
              "      <td>0.987700</td>\n",
              "      <td>0.001457</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.351657</td>\n",
              "      <td>0.134493</td>\n",
              "      <td>0.682236</td>\n",
              "      <td>0.019508</td>\n",
              "      <td>relu</td>\n",
              "      <td>5</td>\n",
              "      <td>Adam</td>\n",
              "      <td>{'activation': 'relu', 'epochs': 5, 'optimizer...</td>\n",
              "      <td>0.986250</td>\n",
              "      <td>0.989833</td>\n",
              "      <td>0.979667</td>\n",
              "      <td>0.979417</td>\n",
              "      <td>0.987000</td>\n",
              "      <td>0.984433</td>\n",
              "      <td>0.004170</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.177941</td>\n",
              "      <td>0.385384</td>\n",
              "      <td>0.704100</td>\n",
              "      <td>0.018219</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>{'activation': 'relu', 'epochs': 10, 'optimize...</td>\n",
              "      <td>0.988750</td>\n",
              "      <td>0.992583</td>\n",
              "      <td>0.986333</td>\n",
              "      <td>0.985250</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>0.988383</td>\n",
              "      <td>0.002537</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.498889</td>\n",
              "      <td>0.216222</td>\n",
              "      <td>0.693315</td>\n",
              "      <td>0.016239</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>Adam</td>\n",
              "      <td>{'activation': 'relu', 'epochs': 10, 'optimize...</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>0.990333</td>\n",
              "      <td>0.987583</td>\n",
              "      <td>0.985333</td>\n",
              "      <td>0.988750</td>\n",
              "      <td>0.988200</td>\n",
              "      <td>0.001679</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.123541</td>\n",
              "      <td>0.308136</td>\n",
              "      <td>0.718995</td>\n",
              "      <td>0.032497</td>\n",
              "      <td>tanh</td>\n",
              "      <td>5</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>{'activation': 'tanh', 'epochs': 5, 'optimizer...</td>\n",
              "      <td>0.985417</td>\n",
              "      <td>0.982417</td>\n",
              "      <td>0.986417</td>\n",
              "      <td>0.984583</td>\n",
              "      <td>0.984917</td>\n",
              "      <td>0.984750</td>\n",
              "      <td>0.001321</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13.052823</td>\n",
              "      <td>0.333553</td>\n",
              "      <td>0.697452</td>\n",
              "      <td>0.037246</td>\n",
              "      <td>tanh</td>\n",
              "      <td>5</td>\n",
              "      <td>Adam</td>\n",
              "      <td>{'activation': 'tanh', 'epochs': 5, 'optimizer...</td>\n",
              "      <td>0.987083</td>\n",
              "      <td>0.985500</td>\n",
              "      <td>0.985500</td>\n",
              "      <td>0.982583</td>\n",
              "      <td>0.986333</td>\n",
              "      <td>0.985400</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>28.179797</td>\n",
              "      <td>0.263469</td>\n",
              "      <td>0.692685</td>\n",
              "      <td>0.008468</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>{'activation': 'tanh', 'epochs': 10, 'optimize...</td>\n",
              "      <td>0.989417</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.988333</td>\n",
              "      <td>0.985750</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.988117</td>\n",
              "      <td>0.001405</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26.136947</td>\n",
              "      <td>0.273603</td>\n",
              "      <td>0.721142</td>\n",
              "      <td>0.019539</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10</td>\n",
              "      <td>Adam</td>\n",
              "      <td>{'activation': 'tanh', 'epochs': 10, 'optimize...</td>\n",
              "      <td>0.988750</td>\n",
              "      <td>0.988250</td>\n",
              "      <td>0.986583</td>\n",
              "      <td>0.983000</td>\n",
              "      <td>0.989167</td>\n",
              "      <td>0.987150</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0      13.451987      0.187093  ...        0.001457                4\n",
              "1      12.351657      0.134493  ...        0.004170                8\n",
              "2      26.177941      0.385384  ...        0.002537                1\n",
              "3      24.498889      0.216222  ...        0.001679                2\n",
              "4      14.123541      0.308136  ...        0.001321                7\n",
              "5      13.052823      0.333553  ...        0.001527                6\n",
              "6      28.179797      0.263469  ...        0.001405                3\n",
              "7      26.136947      0.273603  ...        0.002253                5\n",
              "\n",
              "[8 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}